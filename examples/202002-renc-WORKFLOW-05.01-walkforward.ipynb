{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import os.path, sys\n",
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"__name__ =\" + __name__ )\\nif __name__ == \"__main__\":\\n   print(\"Hello world\")     \\n   print(\"sys.argv: \", sys.argv) \\n   print(os.path.abspath(sys.argv[0]))\\n   inSampleOptimization() \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# https://ntguardian.wordpress.com/2017/06/19/walk-forward-analysis-demonstration-backtrader/\n",
    "class TimeSeriesSplitImproved(TimeSeriesSplit):\n",
    "    \"\"\"Time Series cross-validator\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals, in train/test sets.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide `.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of splits. Must be at least 1.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.model_selection import TimeSeriesSplit\n",
    "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    >>> y = np.array([1, 2, 3, 4])\n",
    "    >>> tscv = TimeSeriesSplit(n_splits=3)\n",
    "    >>> print(tscv)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    TimeSeriesSplit(n_splits=3)\n",
    "    >>> for train_index, test_index in tscv.split(X):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [0 1 2] TEST: [3]\n",
    "    >>> for train_index, test_index in tscv.split(X, fixed_length=True):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [1] TEST: [2]\n",
    "    TRAIN: [2] TEST: [3]\n",
    "    >>> for train_index, test_index in tscv.split(X, fixed_length=True,\n",
    "    ...     train_splits=2):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [1 2] TEST: [3]\n",
    " \n",
    "    Notes\n",
    "    -----\n",
    "    When ``fixed_length`` is ``False``, the training set has size\n",
    "    ``i * train_splits * n_samples // (n_splits + 1) + n_samples %\n",
    "    (n_splits + 1)`` in the ``i``th split, with a test set of size\n",
    "    ``n_samples//(n_splits + 1) * test_splits``, where ``n_samples``\n",
    "    is the number of samples. If fixed_length is True, replace ``i``\n",
    "    in the above formulation with 1, and ignore ``n_samples %\n",
    "    (n_splits + 1)`` except for the first training set. The number\n",
    "    of test sets is ``n_splits + 2 - train_splits - test_splits``.\n",
    "    \"\"\"\n",
    " \n",
    "    def split(self, X, y=None, groups=None, fixed_length=False,\n",
    "              train_splits=1, test_splits=1):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like, with shape (n_samples,), optional\n",
    "            Always ignored, exists for compatibility.\n",
    "        fixed_length : bool, hether training sets should always have\n",
    "            common length\n",
    "        train_splits : positive int, for the minimum number of\n",
    "            splits to include in training sets\n",
    "        test_splits : positive int, for the number of splits to\n",
    "            include in the test set\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        train_splits, test_splits = int(train_splits), int(test_splits)\n",
    "        if n_folds > n_samples:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds ={0} greater\"\n",
    "                 \" than the number of samples: {1}.\").format(n_folds,\n",
    "                                                             n_samples))\n",
    "        #if (n_folds - train_splits - test_splits)  0 and test_splits > 0):\n",
    "        #    raise ValueError(\n",
    "        #        (\"Both train_splits and test_splits must be positive\"\n",
    "        #         \" integers.\"))\n",
    "        indices = np.arange(n_samples)\n",
    "        split_size = (n_samples // n_folds)\n",
    "        test_size = split_size * test_splits\n",
    "        train_size = split_size * train_splits\n",
    "        test_starts = range(train_size + n_samples % n_folds,\n",
    "                            n_samples - (test_size - split_size),\n",
    "                            split_size)\n",
    "        if fixed_length:\n",
    "            for i, test_start in zip(range(len(test_starts)),\n",
    "                                     test_starts):\n",
    "                rem = 0\n",
    "                if i == 0:\n",
    "                    rem = n_samples % n_folds\n",
    "                yield (indices[(test_start - train_size - rem):test_start],\n",
    "                       indices[test_start:test_start + test_size])\n",
    "        else:\n",
    "            for test_start in test_starts:\n",
    "                yield (indices[:test_start],\n",
    "                    indices[test_start:test_start + test_size])\n",
    "                \n",
    "llNetValue = {0:{0:0} }\n",
    "print(llNetValue)\n",
    "# Create a Stratey\n",
    "class TestStrategy(bt.Strategy):\n",
    "    params = (\n",
    "        ('maperiod', 15),       # fast\n",
    "        ('printlog', False), # False\n",
    "        ('emaPeriod', 20),      # slow\n",
    "        (\"optimize\", False), \n",
    "        (\"optimize_fs\", (15, 20))\n",
    "    )\n",
    "    nTradeCount = 0\n",
    "    \n",
    "    def log(self, txt, dt=None, doprint=False):\n",
    "        ''' Logging function fot this strategy'''\n",
    "        if self.params.printlog or doprint:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            print('%s, %s' % (dt.isoformat(), txt))\n",
    "\n",
    "    def __init__(self):\n",
    "        # Keep a reference to the \"close\" line in the data[0] dataseries\n",
    "        self.dataclose = self.datas[0].close\n",
    "\n",
    "        # To keep track of pending orders and buy price/commission\n",
    "        self.order = None\n",
    "        self.buyprice = None\n",
    "        self.buycomm = None\n",
    "\n",
    "        # Add a MovingAverageSimple indicator\n",
    "        # self.datas[0] equal self.data\n",
    "        self.sma = bt.indicators.SimpleMovingAverage(\n",
    "            self.datas[0], period=self.params.maperiod)\n",
    "        self.ema1 = bt.indicators.ExponentialMovingAverage( \n",
    "                period = self.params.emaPeriod)\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log(\n",
    "                    'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n",
    "                    (order.executed.price,\n",
    "                     order.executed.value,\n",
    "                     order.executed.comm))\n",
    "\n",
    "                self.buyprice = order.executed.price\n",
    "                self.buycomm = order.executed.comm\n",
    "            else:  # Sell\n",
    "                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n",
    "                         (order.executed.price,\n",
    "                          order.executed.value,\n",
    "                          order.executed.comm))\n",
    "\n",
    "            self.bar_executed = len(self)\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "\n",
    "        # Write down: no pending order\n",
    "        self.order = None\n",
    "\n",
    "    def notify_trade(self, trade):\n",
    "        if not trade.isclosed:\n",
    "            return\n",
    "\n",
    "        self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %\n",
    "                 (trade.pnl, trade.pnlcomm))\n",
    "        self.nTradeCount = self.nTradeCount + 1\n",
    "        \n",
    "    def next(self):\n",
    "        # Simply log the closing price of the series from the reference\n",
    "        self.log('Close, %.2f' % self.dataclose[0])\n",
    "\n",
    "        # Check if an order is pending ... if yes, we cannot send a 2nd one\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        # Check if we are in the market\n",
    "        if not self.position:\n",
    "            # self.dataclose[0] == self.data.close[0]\n",
    "            #print(\"dataclose[0]=%.2f, sma[0]=%.2f\" % (self.dataclose[0], self.sma[0]))\n",
    "            # Not yet ... we MIGHT BUY if ...\n",
    "            if self.dataclose[0] > self.sma[0] and self.dataclose[0] > self.ema1[0] and self.sma[0] > self.ema1[0]:\n",
    "                # BUY, BUY, BUY!!! (with all possible default parameters)\n",
    "                self.log('BUY CREATE, %.2f' % self.dataclose[0])\n",
    "                # Keep track of the created order to avoid a 2nd order\n",
    "                self.order = self.buy()\n",
    "        else:\n",
    "            if self.dataclose[0] < self.sma[0] and self.dataclose[0] < self.ema1[0] and self.sma[0] < self.ema1[0]:\n",
    "                # SELL, SELL, SELL!!! (with all possible default parameters)\n",
    "                self.log('SELL CREATE, %.2f' % self.dataclose[0])\n",
    "                # Keep track of the created order to avoid a 2nd order\n",
    "                self.order = self.sell()\n",
    "\n",
    "    def stop(self):\n",
    "        self.log('(SMA Period %2d, EMA Period %2d) Ending Value %.2f, tradeCount %d' %\n",
    "                 (self.params.maperiod, self.params.emaPeriod, self.broker.getvalue(), self.nTradeCount)\n",
    "                 , doprint=True)\n",
    "        #llNetValue[self.params.maperiod][self.params.emaPeriod] = self.broker.getvalue()\n",
    "        \n",
    "class FixedSlippageAndCommisionScheme(bt.CommInfoBase):\n",
    "    '''Use this for both slippage and commissions together'''\n",
    "    params = (\n",
    "        ('commission', 10),\n",
    "        ('stocklike', True),\n",
    "        ('commtype', bt.CommInfoBase.COMM_FIXED),\n",
    "        )\n",
    "\n",
    "    def _getcommission(self, size, price, pseudoexec):\n",
    "        return self.p.commission\n",
    "\n",
    "class AcctStats(bt.Analyzer):\n",
    "    \"\"\"A simple analyzer that get the gain \"\"\"\n",
    "    def __init__(self):\n",
    "        self.startValue = self.strategy.broker.get_value()\n",
    "        self.endValue = None\n",
    "    def stop(self):\n",
    "        self.endValue = self.strategy.broker.get_value()\n",
    "    def get_analysis(self):\n",
    "        return {\"startValue\":self.startValue, \"endValue\":self.endValue, \n",
    "                \"valueGrowth\":self.endValue - self.startValue, \"ratio\": self.endValue / self.startValue } \n",
    "    \n",
    "# renc, \n",
    "# parameter: data sample period   \n",
    "# parameter: simple moving average period, \n",
    "     \n",
    "\n",
    "# after finding the best performing parameters, \n",
    "# apply these parameters for your out-of-sample period.\n",
    "def outOfSample(inMaPeriod, inEmaPeriod, inDfTest, outList, isPlot=False):\n",
    "    print(\"-- Out-of-Sample testing -- \")\n",
    "    # Create a cerebro entity\n",
    "    cerebro = bt.Cerebro()\n",
    "    # Add a strategy\n",
    "    cerebro.addstrategy(TestStrategy, maperiod=inMaPeriod, emaPeriod=inEmaPeriod)\n",
    "    dataFeed = bt.feeds.PandasData(dataname = inDfTest)\n",
    "    # Add the Data Feed to Cerebro\n",
    "    cerebro.adddata(dataFeed)\n",
    "    # Set our desired cash start\n",
    "    cerebro.broker.setcash(100000.0)\n",
    "    cerebro.addsizer(bt.sizers.FixedSize, stake=1000)\n",
    "    # We're trading futures, so we'll use the \"commissions\" to handle both slippage and commissions\n",
    "    slippage_and_comms = FixedSlippageAndCommisionScheme()\n",
    "    cerebro.broker.addcommissioninfo(slippage_and_comms)\n",
    "\n",
    "    # Print out the starting conditions\n",
    "    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "    # Run over everything\n",
    "    results = cerebro.run()\n",
    "    # Print out the final result\n",
    "    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue()) \n",
    "    outList.append( cerebro.broker.getvalue() )\n",
    "    if isPlot:\n",
    "        cerebro.plot(volume=False, iplot=False) # do not plot, otherwise block the following exexc\n",
    "    \n",
    "    \n",
    "# Load data\n",
    "# CL: crude oil; GC: gold; ES: S&P 500. All futures        \n",
    "fname_symbol = \"CL\" # \"GC\" # \"ES\" #'CL' \n",
    "folder_name = '5min'\n",
    "suffix = '5min_20160103_20190405'\n",
    "\n",
    "# using the dataframe will be more flecible.\n",
    "df = pd.read_parquet(os.path.join('../data/processed/{}/'.format(folder_name),\n",
    "                                  '{}_{}.parquet'.format(fname_symbol, suffix)))\n",
    "df = (df.resample('1h', label='left', base=18).agg(\n",
    "        {'Open': 'first', 'High': 'max', 'Low': 'min', \n",
    "         'Close': 'last', 'Volume': 'sum'}))\n",
    "df.columns = [col_name.lower() for col_name in df.columns]\n",
    "df = df.dropna()\n",
    "dfTrain = df['2016-01-01':'2018-01-01']\n",
    "dfTest = df['2018-01-01':'2018-06-01']\n",
    "      \n",
    "def inSampleOptimization():\n",
    "    print(\"In-Sample training\")\n",
    "\n",
    "    #data = bt.feeds.PandasData(dataname = df['2016-01-01':'2018-01-01'])\n",
    "    #data = bt.feeds.PandasData(dataname = dfTrain, name=(fname_symbol+\"_\"+folder_name) )\n",
    "    \n",
    "    tscv = TimeSeriesSplitImproved(10)\n",
    "    #split = tscv.split(datafeeds[\"AAPL\"], fixed_length=True, train_splits=2) # from tutorial\n",
    "    split = tscv.split(dfTrain, fixed_length=True, train_splits=2)\n",
    "    # to show the dataset \n",
    "    \n",
    "    outResults = list()\n",
    "    \n",
    "    iCountTrain = 0\n",
    "    for train, test in split:\n",
    "        #print(train[0], \"-\", train[-1], test[0], \"-\", test[-1])\n",
    "        print(\"-- Training : \" + str(iCountTrain) + \" --\\n\")\n",
    "        iCountTrain = iCountTrain + 1\n",
    "        \n",
    "        # Create a cerebro entity\n",
    "        cerebro = bt.Cerebro()\n",
    "         \n",
    "        # Add a strategy, this is different from level02\n",
    "        strats = cerebro.optstrategy(\n",
    "            TestStrategy\n",
    "            , maperiod=range(1, 21)\n",
    "            , emaPeriod=range(11, 31)\n",
    "        )\n",
    "        \n",
    "        # Add the Data Feed to Cerebro\n",
    "        #cerebro.adddata(data) # only for one data source before walk forward\n",
    "        dfTrainWF = df.iloc[train]\n",
    "        dataFeedTrainWF = bt.feeds.PandasData(dataname = dfTrainWF)\n",
    "        cerebro.adddata(dataFeedTrainWF)\n",
    "        # Set our desired cash start\n",
    "        startCash = 100000.0\n",
    "        cerebro.broker.setcash( startCash )    \n",
    "        # Add a FixedSize sizer according to the stake\n",
    "        cerebro.addsizer(bt.sizers.FixedSize, stake=1000)\n",
    "        \n",
    "        # We're trading futures, so we'll use the \"commissions\" to handle both slippage and commissions\n",
    "        slippage_and_comms = FixedSlippageAndCommisionScheme()\n",
    "        cerebro.broker.addcommissioninfo(slippage_and_comms)    \n",
    "        \n",
    "        # Print out the starting conditions\n",
    "        print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())    \n",
    "        # Run over everything\n",
    "        #results = cerebro.run(maxcpus=1)\n",
    "        results = cerebro.run(optreturn=False)\n",
    "        \"\"\"    \n",
    "        # Print out the final result\n",
    "        print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue()) \n",
    "        print(\"type(results), \", type(results), \", len:\", len(results), \n",
    "              \", len of results[0]: \", len(results[0]), \", type: \", type(results[0])\n",
    "              )\n",
    "        print( results[0] )\n",
    "        print( results[0][0] )\n",
    "        optReturn = results[0][0] \n",
    "        print( dir(optReturn) )\n",
    "        print( \"analyzers, \", optReturn.analyzers, dir(optReturn.analyzers) )\n",
    "        print( \"p, \", optReturn.p, dir(optReturn.analyzers) )\n",
    "        print( \"params, \", dir(optReturn.params), optReturn.params.maperiod, optReturn.params.emaPeriod ) \n",
    "        \"\"\"\n",
    "        # generate results\n",
    "        result_list = []\n",
    "        for run in results:\n",
    "            for strategy in run:\n",
    "                value = round(strategy.broker.getvalue(), 2)\n",
    "                PnL = round(value - startCash, 2)\n",
    "                result_list.append([strategy.params.maperiod, strategy.params.emaPeriod, PnL])\n",
    "        by_PnL = sorted(result_list, key=lambda x: x[2], reverse=True)\n",
    "        print(by_PnL)\n",
    "        \n",
    "        # testing \n",
    "        dfTestWF = df.iloc[test]\n",
    "        outValue = list()\n",
    "        outOfSample(by_PnL[0][0], by_PnL[0][1], dfTestWF, outValue)\n",
    "        outResults.append([by_PnL[0][0], by_PnL[0][1], outValue[0]])\n",
    "    #\n",
    "    print(\"-- \\n\")\n",
    "    print(\"-- print the results --\\n\")\n",
    "    outResults_byPnL = sorted(outResults, key=lambda x: x[2], reverse=True)\n",
    "    print(outResults_byPnL)\n",
    "    print(\"-- run the test with best para -- \\n\")\n",
    "    outOfSample( outResults_byPnL[0][0], outResults_byPnL[0][1], dfTest, (),True)\n",
    "    \n",
    "    print(\"-- end --\\n\")\n",
    "\n",
    "\"\"\"\n",
    "print(\"__name__ =\" + __name__ )\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Hello world\")     \n",
    "    print(\"sys.argv: \", sys.argv) \n",
    "    print(os.path.abspath(sys.argv[0]))\n",
    "    inSampleOptimization() \n",
    "\"\"\"         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Out-of-Sample testing -- \n",
      "Starting Portfolio Value: 100000.00\n",
      "2018-06-01, (SMA Period 13, EMA Period 26) Ending Value 104920.00, tradeCount 31\n",
      "Final Portfolio Value: 104920.00\n"
     ]
    }
   ],
   "source": [
    "outOfSample( 13, 26, dfTest, list(),True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
